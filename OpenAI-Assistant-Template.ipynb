{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can use this as a template to quickly create an Assistant using OpenAI's Assistant API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21fdf7e-c27e-493c-b9d2-dbcc6ef61abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from utils.modules import *\n",
    "load_dotenv() # Load .env file\n",
    "from openai import OpenAI\n",
    "client = OpenAI() # Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Assistant using assistant id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhagavad is ready to go!\n"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.retrieve(\"asst_n14fsD7ddyPgc4h3ee2wbnW1\") # Retrieve Assistant\n",
    "print(assistant.name + \" is ready to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set ```get_previous_thread = True``` if you want to use a previous thread. Set ```get_previous_thread = False``` to create a new thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new conversation or retrieve an existing one\n",
    "get_previous_thread = False\n",
    "thread_id_to_use = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the previous conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New chat created with ID: thread_51umF2B7HOn5vTJWsT4WSR5C\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the previous conversation thread\n",
    "\n",
    "if get_previous_thread:\n",
    "    thread = get_chat(client, thread_id_to_use)\n",
    "    print(\"Chat retrieved with ID: \" + thread.id)\n",
    "    print(thread)\n",
    "else:\n",
    "    thread = start_new_chat(client)\n",
    "    print(\"New chat created with ID: \" + thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new message into thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message to send to the assistant\n",
    "\n",
    "content = \"Hi, my name is Pranav. I am here for your advice.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreadMessage(id='msg_BhkqzVrZHanKVkpxWmwJpBPw', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Hi, my name is Pranav. I am here for your advice.'), type='text')], created_at=1699363871, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_51umF2B7HOn5vTJWsT4WSR5C')\n"
     ]
    }
   ],
   "source": [
    "# Add the message into the thread\n",
    "\n",
    "new_message = add_message(client, thread, content)\n",
    "print(new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the thread with the new message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_flilSuNX1kV5PvoNXsI09S7N', assistant_id='asst_n14fsD7ddyPgc4h3ee2wbnW1', cancelled_at=None, completed_at=None, created_at=1699363873, expires_at=1699364473, failed_at=None, file_ids=['file-yt9TUOLRPMvM41VLT0GFScnB'], instructions='You are Lord Krishna, the Hindu God. You need to advise as if you are talking to Arjuna but do not call me Arjuna. You need to talk like Lord Krishna. Your answers should be directly based from the Gita from the file given to you.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_51umF2B7HOn5vTJWsT4WSR5C', tools=[ToolAssistantToolsRetrieval(type='retrieval')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the thread with the assistant with the new message\n",
    "\n",
    "run_chat(client, thread, assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the below code everytime you need to see the new chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: Hi, my name is Pranav. I am here for your advice.\n",
      "ASSISTANT: Welcome, Pranav. It is good that you seek counsel and are open to wisdom. Share with me what troubles your heart or mind, and I shall endeavor to guide you with the insights drawn from the ancient and timeless teachings of the Gita. How may I assist you on your path?\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the chat history\n",
    "\n",
    "history = get_messages_in_chat(client, thread)\n",
    "messages = history.data[::-1]\n",
    "for i in messages:\n",
    "    print(i.role.upper() + \": \"+ i.content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
